import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_curve, auc
)
from ft_engineering import create_feature_pipeline, split_dataset


# Preparación de datos y pipeline
df = pd.read_csv("../telecom_churn.csv")

preprocessor = create_feature_pipeline()
X_train, X_test, y_train, y_test = split_dataset(df)

X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

# Entrenamiento de modelos
# Modelo base: Regresión logística
log_model = LogisticRegression(max_iter=1000, solver='liblinear')
log_model.fit(X_train_transformed, y_train)
y_pred_log = log_model.predict(X_test_transformed)

# Modelo alternativo: Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_transformed, y_train)
y_pred_rf = rf_model.predict(X_test_transformed)

# Evaluación cuantitativa
def evaluar_modelo(nombre, y_test, y_pred):
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(f"\nModelo: {nombre}")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall: {rec:.4f}")
    print(f"F1-score: {f1:.4f}")

    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"Matriz de confusión - {nombre}")
    plt.xlabel("Predicho")
    plt.ylabel("Real")
    plt.show()

# Evaluar ambos
evaluar_modelo("Regresión Logística", y_test, y_pred_log)
evaluar_modelo("Random Forest", y_test, y_pred_rf)

# Comparación visual
y_pred_log_prob = log_model.predict_proba(X_test_transformed)[:, 1]
y_pred_rf_prob = rf_model.predict_proba(X_test_transformed)[:, 1]

fpr_log, tpr_log, _ = roc_curve(y_test, y_pred_log_prob)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf_prob)

roc_auc_log = auc(fpr_log, tpr_log)
roc_auc_rf = auc(fpr_rf, tpr_rf)

plt.figure(figsize=(6,5))
plt.plot(fpr_log, tpr_log, label=f"Logistic Regression (AUC = {roc_auc_log:.2f})")
plt.plot(fpr_rf, tpr_rf, label=f"Random Forest (AUC = {roc_auc_rf:.2f})")
plt.plot([0,1],[0,1],'--',color='gray')
plt.title("Curva ROC - Comparación de Modelos")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

#Reporte de clasificación y conclusiones
print("\nReporte de clasificación")
print(classification_report(y_test, y_pred_log))

print("\nReporte de Random Forest")
print(classification_report(y_test, y_pred_rf))

resultados = pd.DataFrame({
    "Modelo": ["Regresión Logística", "Random Forest"],
    "Accuracy": [
        accuracy_score(y_test, y_pred_log),
        accuracy_score(y_test, y_pred_rf)
    ],
    "F1-Score": [
        f1_score(y_test, y_pred_log),
        f1_score(y_test, y_pred_rf)
    ]
})

print("\nResumen comparativo de modelos:")
print(resultados)

# Insights finales
print("\nINSIGHTS DEL ANÁLISIS:")
print("El modelo Random Forest presenta mejor desempeño general (F1 y AUC) que la regresión logística.")
print(" Sin embargo, la regresión logística ofrece interpretabilidad y tiempos de entrenamiento más rápidos.")
print(" Según las métricas, Random Forest es más robusto para capturar clientes propensos al churn.")
print(" Se recomienda usar Random Forest para producción si se prioriza la precisión del modelo.")
